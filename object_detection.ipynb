{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjYmSiBXYNLOr7mFnF1TRQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYRjr1RM2j-c"
      },
      "source": [
        "# Download the data\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!tar --gunzip --extract --verbose --file=annotations.tar.gz\n",
        "!tar --gunzip --extract --verbose --file=images.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al2SHEwC_Ozu",
        "outputId": "53c3ed94-f707-4ba3-e71e-243ac3b47d31"
      },
      "source": [
        "# Preprocess data into csv files \n",
        "from preprocess_data import main\n",
        "main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class Dog: 2498 images\n",
            "class Cat: 1188 images\n",
            "3686/3686\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmYO8F37371B"
      },
      "source": [
        "# Import Libraries and Define model\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
        "from tensorflow.keras.layers import Conv2D, Reshape, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.backend import epsilon\n",
        "\n",
        "# 0.35, 0.5, 0.75, 1.0\n",
        "ALPHA = 0.75\n",
        "\n",
        "# 96, 128, 160, 192, 224\n",
        "IMAGE_SIZE = 96\n",
        "\n",
        "CLASSES = 2\n",
        "\n",
        "def create_model(trainable=False):\n",
        "    model = MobileNetV2(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, alpha=ALPHA)\n",
        "\n",
        "    # to freeze layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    out = model.layers[-1].output\n",
        "\n",
        "    x = Conv2D(4, kernel_size=3)(out)\n",
        "    x = Reshape((4,), name=\"coords\")(x)\n",
        "\n",
        "    y = GlobalAveragePooling2D()(out)\n",
        "    y = Dense(CLASSES, name=\"classes\", activation=\"softmax\")(y)\n",
        "\n",
        "    return Model(inputs=model.input, outputs=[x, y])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKn-uSiIAkIf"
      },
      "source": [
        "# Define loss functions for object detection  \n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def log_mse(y_true, y_pred):\n",
        "  return tf.reduce_mean(tf.math.log1p(tf.math.squared_difference(y_pred, y_true)), axis=-1)\n",
        "\n",
        "def focal_loss(alpha=0.9, gamma=2):\n",
        "  def focal_loss_with_logits(logits, targets, alpha, gamma, y_pred):\n",
        "    weight_a = alpha * (1 - y_pred) ** gamma * targets\n",
        "    weight_b = (1 - alpha) * y_pred ** gamma * (1 - targets)\n",
        "    \n",
        "    return (tf.math.log1p(tf.exp(-tf.abs(logits))) + tf.nn.relu(-logits)) * (weight_a + weight_b) + logits * weight_b\n",
        "\n",
        "  def loss(y_true, y_pred):\n",
        "    y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
        "    logits = tf.math.log(y_pred / (1 - y_pred))\n",
        "\n",
        "    loss = focal_loss_with_logits(logits=logits, targets=y_true, alpha=alpha, gamma=gamma, y_pred=y_pred)\n",
        "\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFSx04yO-cxi"
      },
      "source": [
        "# Model Summary\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi4w_AtU-ptP"
      },
      "source": [
        "# Data Generator and Validations\n",
        "from data_generator import DataGenerator, Validation\n",
        "\n",
        "TRAIN_CSV = \"train.csv\"\n",
        "VALIDATION_CSV = \"validation.csv\"\n",
        "\n",
        "train_datagen = DataGenerator(TRAIN_CSV)\n",
        "validation_datagen = Validation(generator=DataGenerator(VALIDATION_CSV))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ7IKH52BceR"
      },
      "source": [
        "# Launch model training\n",
        "\n",
        "EPOCHS = 70\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 15\n",
        "\n",
        "MULTI_PROCESSING = False\n",
        "THREADS = 1\n",
        "\n",
        "optimizer = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(loss={\"coords\" : log_mse, \"classes\" : focal_loss()}, loss_weights={\"coords\" : 1, \"classes\" : 1}, optimizer=optimizer, metrics=[])\n",
        "checkpoint = ModelCheckpoint(\"model-iou.h5\", monitor=\"val_iou\", verbose=1, save_best_only=False,\n",
        "                                 save_weights_only=True, mode=\"max\")\n",
        "stopEarly = EarlyStopping(monitor=\"val_iou\", patience=PATIENCE, mode=\"max\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_iou\", factor=0.2, patience=10, min_lr=1e-7, verbose=1, mode=\"max\")\n",
        "\n",
        "model.fit(train_datagen,\n",
        "          epochs=EPOCHS,\n",
        "          callbacks=[validation_datagen, checkpoint, reduce_lr, stopEarly],\n",
        "          workers=THREADS,\n",
        "          use_multiprocessing=MULTI_PROCESSING,\n",
        "          shuffle=True,\n",
        "          verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m1iQj7OINrV"
      },
      "source": [
        "#Test Model\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "WEIGHTS_FILE = \"model-iou.h5\"\n",
        "IMAGES = \"images/*jpg\"\n",
        "\n",
        "model = create_model()\n",
        "model.load_weights(WEIGHTS_FILE)\n",
        "\n",
        "class_names = {0:'Dog', 1:'Cat'}\n",
        "\n",
        "for filename in glob.glob(IMAGES):\n",
        "  unscaled = cv2.imread(filename)\n",
        "  image_height, image_width, _ = unscaled.shape\n",
        "\n",
        "  image = cv2.resize(unscaled, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  feat_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
        "\n",
        "  region, class_id = model.predict(x=np.array([image]))\n",
        "  region = region[0]\n",
        "\n",
        "  x0 = int(region[0] * image_width / IMAGE_SIZE)\n",
        "  y0 = int(region[1]  * image_height / IMAGE_SIZE)\n",
        "\n",
        "  x1 = int((region[0] + region[2]) * image_width / IMAGE_SIZE)\n",
        "  y1 = int((region[1] + region[3]) * image_height / IMAGE_SIZE)\n",
        "\n",
        "  class_id = np.argmax(class_id, axis=1)[0]\n",
        "\n",
        "  cv2.rectangle(unscaled, (x0, y0), (x1, y1), (0, 0, 255), 1)\n",
        "  cv2.putText(unscaled, \"class: {}\".format(class_names[class_id]), (x0, y0), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "  cv2_imshow(unscaled)\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzzsHQ7fIx85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}